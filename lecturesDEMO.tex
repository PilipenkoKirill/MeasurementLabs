
%!TEX program = xelatex.exe
\documentclass[14pt,a4paper]{article}
\usepackage[pdftex,
    pdfauthor={К.С.~Пилипенко},
    pdftitle={Лекции по ООРИ},
    pdfsubject={The Subject},
    pdfkeywords={Первое ключевое слово, второе ключевое слово},
    pdfproducer={LuaLatex with hyperref},
    pdfcreator={Lualatex},
    hidelinks
]{hyperref}
%%%%%%%%%%%%%%Пользовательские команды%%%%%%%%%
\setlength{\abovedisplayskip}{-15pt}
\setlength{\belowdisplayskip}{0pt}
\setlength{\abovedisplayshortskip}{0pt}
\setlength{\belowdisplayshortskip}{0pt}
% \usepackage[nodisplayskipstretch]{setspace} %Устанавливает интервал между формулами
% \setstretch{1.1}
\usepackage{latexsym,amsmath,amssymb,amsbsy,graphicx}
\usepackage{icomma}
\usepackage[version=4]{mhchem} % the canonical chemistry package (example: \ce{^{32}_{15}P})
\usepackage{graphicx}
\graphicspath{{images/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
%%%%%%%%%%%%%%%%%%%%%%%%Оформление по ГОСТУ
\usepackage{fontspec}
\setmainfont[Renderer=Basic,Ligatures={TeX}]{Times New Roman}
\usepackage[english,russian]{babel} %Поддержка русской локализации
\usepackage[14pt]{extsizes} % для того чтобы задать нестандартный 14-ый размер шрифта
\usepackage{indentfirst} %Задаёт отступ самого первого абзаца
\setlength\parindent{1.25cm}
\usepackage[a4paper, left=3cm, top=1.5cm, right=1.5cm, bottom=2cm]{geometry}
\usepackage{setspace}
%\sloppy %Выравнивание текст по ширине и решение проблемы переполнением строки
\onehalfspacing %Полуторный интервал
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Лекции по ООРИ}
\author{\href{mailto:www-kirill.pilipenko@yandex.ru}{К.С.~Пилипенко}} %Через \and можно добавить ещё авторов
\date{\selectlanguage{russian}\today}
\begin{document}
\maketitle
Этапы статистического анализа
\begin{enumerate}
    \item Что изучается? Какие статистические гипотезы?
    \item Какие данные?
    \item Выбор критерия.
    \item Интерпретация результатов
    \item Вывод
\end{enumerate}

\section{Стандартная ошибка средней арифметической}
Стандартная ошибка средней арифметической
Описание данных

Среднее арифметическое, как известно, используется для получения обобщающей характеристики некоторого набора данных. Если данные более-менее однородны и в них нет аномальных наблюдений (выбросов), то среднее хорошо обобщает данные, сведя к минимуму влияние случайных факторов (они взаимопогашаются при сложении).

Когда анализируемые данные представляют собой выборку (которая состоит из случайных значений), то среднее арифметическое часто (но не всегда) выступает в роли приближенной оценки математического ожидания. Почему приближенной? Потому что среднее арифметическое – это величина, которая зависит от набора случайных чисел, и, следовательно, сама является случайной величиной. При повторных экспериментах (даже в одних и тех же условиях) средние будут отличаться друг от друга.

Для того, чтобы на основе статистического анализа данных делать корректные выводы, необходимо оценить возможный разброс полученного результата. Для этого рассчитываются различные показатели вариации. Но то исходные данные. И как мы только что установили, среднее арифметическое также обладает разбросом, который необходимо оценить и учитывать в дальнейшем (в выводах, в выборе метода анализа и т.д.).

Интуитивно понятно, что разброс средней должен быть как-то связан с разбросом исходных данных. Основной характеристикой разброса средней выступает та же дисперсия.

\section{Математическое ожидание}
Свойства математического ожидания:
\begin{enumerate}
    \item M[X+Y] = M[X] + M[Y], где P(X|Y) = P(X) и P(Y|X) = P(Y) \\
    \textit{Доказательство}
    \begin{multline*}
        M[X+Y]  = \sum\limits_i\sum\limits_j(x_i + y_i)p_{xi}p_{yj} = \\ \sum\limits_i\sum\limits_jx_ip_{xi}p_{yj} + \sum\limits_i\sum\limits_jy_jp_{xi}p_{yj} = \\
        \sum\limits_ix_ip_{xi}\sum\limits_jp_{yj} + \sum\limits_jp_{yj}y_j\sum\limits_ip_{xi}
    \end{multline*}
    \item $M[XY] =  M[X]M[Y]$ \\
    \textit{Доказательство}
    \begin{multline*}
        M[XY] = \sum\limits_i\sum\limits_jx_i y_ip_{xi}p_{yj} = \sum\limits_ix_ip_{xi}\sum\limits_jx_jp_{xj} = M[X]M[Y] 
    \end{multline*}
\end{enumerate}

Свойства дисперсии:
\begin{enumerate}
    \item $D[X] = M[X^2] - M^2[X]$;
    \item $D[a] = M[a^2] - M^2[a] = a^2 - a^2 = 0$;
    \item $D[X+Y] = D[X] + D[Y]$ \\
    \textit{Доказательство} \\
    \begin{multline*}
        D[X+Y] = M[(X+Y)^2] - M^2[X+Y] = \\ = M[X^2]+ 2M[XY] + M[Y^2] - (M^2[X]+2M[X]M[Y]+M^2[Y]) = \\ = M[X^2] - M^2[X] + M[Y^2] - M^2[Y] = D[X] + D[Y]
    \end{multline*}
    Замечание $D[X-Y] = D[X] + D[Y]$!
    \item $D[X+a] = D[X]$;
    \item $D[aX] = a^2D[X]$
\end{enumerate}
Дисперсия выборочных данных – это средний квадрат отклонения от средней, и рассчитать ее по исходным данным не составляет труда, например, в Excel предусмотрены специальные функции. Однако, как же рассчитать дисперсию средней, если в распоряжении есть только одна выборка и одно среднее арифметическое?
Расчет дисперсии и стандартной ошибки средней арифметической

Чтобы получить дисперсию средней арифметической нет необходимости проводить множество экспериментов, достаточно иметь только одну выборку. Это легко доказать. Для начала вспомним, что средняя арифметическая (простая) рассчитывается по формуле:

формула средней арифметической

где xi – значения переменной,
n – количество значений.

Теперь учтем два свойства дисперсии, согласно которым, 1) — постоянный множитель можно вынести за знак дисперсии, возведя его в квадрат и 2) — дисперсия суммы независимых случайных величин равняется сумме соответствующих дисперсий. Предполагается, что каждое случайное значение xi обладает одинаковым разбросом, поэтому несложно вывести формулу дисперсии средней арифметической:

Формула дисперсии средней арифметической

Используя более привычные обозначения, формулу записывают как:

Дисперсия средней арифметической

где σ2 – это дисперсия, случайной величины, причем генеральная.

На практике же, генеральная дисперсия известна далеко не всегда, точнее совсем редко, поэтому в качестве оной используют выборочную дисперсию:

Дисперсия средней арифметической по выборке

Стандартное отклонение средней арифметической называется стандартной ошибкой средней и рассчитывается, как квадратный корень из дисперсии.

Формула стандартной ошибки средней при использовании генеральной дисперсии

Стандартная ошибка средней

Формула стандартной ошибки средней при использовании выборочной дисперсии

Стандартная ошибка средней по выборке

Последняя формула на практике используется чаще всего, т.к. генеральная дисперсия обычно не известна. Чтобы не вводить новые обозначения, стандартную ошибку средней обычно записывают в виде соотношения стандартного отклонения выборки и корня объема выборки.
https://statanaliz.info/statistica/opisanie-dannyx/dispersiya-srednej-arifmetiskoj/
\section{Статистическое определение вероятности. Метод Монте-Карло}
\section{Виды распределений}
\begin{enumerate}
    \item \textbf{Равномерное распределение}
    \textit{Функция распределения}
    \begin{equation}
        f(x) = \begin{cases}
            0, x < a \\
            \frac{x-a}{b-a}, a \leqslant  x < b \\
            1, x \geqslant  b
        \end{cases}
    \end{equation}
    \textit{Плотность распределения}
    \begin{equation}
        \omega(x) = \begin{cases}
            \frac{1}{b-a}, x \in [a,b] \\
            0, x \notin [a,b]\\
        \end{cases}
    \end{equation}
    \item \textbf{Распределение Пуассона}
    Распределение Пуассона описывает дискретную случайную величину, представляющую собой число событий, произошедших за фиксированное время, при условии, что данные события происходят независимо друг от друга с некоторой фиксированной средней интенсивностью. 

    Распределение Пуассона применимо, если:
    \begin{enumerate}
        \item случайная величина принимает только положительные значения, 
        \item если длина интервала (например, t – время наблюдения) стремится к нулю, то вероятность одного события также стремится к нулю,
        \item события, относящиеся к неперекрывающимся интервалам, являются статистически независимыми.
    \end{enumerate} 
    Вероятность наблюдения n событий, произошедших за время t определяется формулой (функция вероятности):
    \begin{equation}
        P_n = \frac{{\bar{n}}^n}{n!}e^{-\bar{n}},
    \end{equation}
    $\bar{n}$ – математическое ожидание случайной величины(среднее количество событий за  промежуток времени t)
    \textit{Плотность распределения}
    \begin{equation}
        \omega(x) = \frac{\text{Г}(n+1,\bar{n})}{n!},
    \end{equation}
    \textbf{Пример.} Устройство состоит из 1000 элементов, работающих независимо один от другого. Вероятность отказа любого элемента в течение времени Т равна 0,002. Найти вероятность того, что за время Т откажут ровно три элемента.
    Решение\\
    Математическое ожидание в этом случае будет определяться как
    \begin{equation}
        N_0 = \sum_{i=1}^{n} P_i,
    \end{equation} 
    где n~---~это число элементов, а $P_i$~---~вероятность выхода из строя одного элемента и тогда $N_0 = 2$. И тогда вероятность выхода из строя трёх элементов будет определяться следующим образом:
    \begin{equation}
        P_3 = \frac{2^3}{3!}e^{-2} \approx 0,18 
    \end{equation} 
    \item Нормальное распределение. Расп-е Гаусса.
    \item Экспоненциальное распределение.
    \item Биномиальное распределение. Расп-е Бернулли.
    \item Геометрическое распределение
\end{enumerate}
\section{Распределение $\chi^2$. Критерий Пирсона}
До конца XIX века нормальное распределение считалась всеобщим законом вариации данных. Однако К. Пирсон заметил, что эмпирические частоты могут сильно отличаться от нормального распределения. Встал вопрос, как это доказать. Требовалось не только графическое сопоставление, которое имеет субъективный характер, но и строгое количественное обоснование.

Так был изобретен критерий $\chi^2$ (хи квадрат), который проверяет значимость расхождения эмпирических (наблюдаемых) и теоретических (ожидаемых) частот. Это произошло в далеком 1900 году, однако критерий и сегодня на ходу. Более того, его приспособили для решения широкого круга задач. Прежде всего, это анализ категориальных данных, т.е. таких, которые выражаются не количеством, а принадлежностью к какой-то категории. Например, класс автомобиля, пол участника эксперимента, вид растения и т.д. К таким данным нельзя применять математические операции вроде сложения и умножения, для них можно только подсчитать частоты.

Плотность распределения $\chi^2$ \cite{Plis2003}:
\begin{equation}
    p_n(z)\begin{cases}
        0,  z<0\\
        \frac{1}{\text{Г}(\frac{n}{2})2^{\frac{n}{2}}}z^\frac{n-2}{2}e^{-\frac{z}{2}}, z>0,
    \end{cases}
\end{equation}
где $\text{Г}(x) = \int\limits_{0}^{\infty} x^{z-1}e^{-z}dz$~---~гамма-функция Эйлера.
Виды распределений
\begin{itemize}
    \item Распределение Стьюдента (t-распределение).
    Необходимые условия для критерия Стьюдента
    \begin{itemize}
        \item Нормальное распределение
        \item Количественные данные
        \item две независимые выборки
    \end{itemize}
    \item  Распределение Фишера
\end{itemize}
% \printbibliography[title={Рекомендуемая литература}]
\end{document}